# GameEval Architecture Diagram

**Generated:** 2025-11-06  
**Purpose:** Visual representation of GameEval's component architecture, data flow, and technology stack.

---

## System Architecture Overview

```mermaid
graph TB
    subgraph "User Layer"
        Browser["ğŸŒ Browser<br/>(React Dashboard)"]
    end

    subgraph "Edge Layer - Cloudflare Workers"
        DashboardWorker["ğŸ“Š Dashboard Worker<br/>(src/index.ts)<br/>Serves UI + RPC Handler"]
        
        subgraph "Orchestration"
            Workflow["âš™ï¸ Cloudflare Workflow<br/>(GameTestPipeline)<br/>4-Phase Coordinator"]
        end
        
        subgraph "Agent Layer"
            TestAgentDO["ğŸ¤– TestAgent DO<br/>(Per Test Instance)<br/>Stateful Test Executor"]
        end
    end

    subgraph "Cloudflare Services"
        BrowserRendering["ğŸ® Browser Rendering<br/>(Stagehand + Playwright)<br/>Autonomous Gameplay"]
        AIGateway["ğŸ§  AI Gateway<br/>(Workers AI + Fallbacks)<br/>15-min Cache"]
        
        subgraph "Data Persistence"
            D1["ğŸ—„ï¸ D1 Database<br/>(SQLite)<br/>Test Metadata"]
            AgentSQL["ğŸ’¾ Agent SQL<br/>(Per-DO Storage)<br/>Decisions & Reasoning"]
            R2["ğŸ“¦ R2 Storage<br/>(Object Store)<br/>Screenshots & Logs"]
        end
    end

    %% User Interactions
    Browser -->|1. Submit Test| DashboardWorker
    DashboardWorker -->|2. Start Pipeline| Workflow
    Browser -.->|WebSocket: Live Updates| TestAgentDO
    
    %% Workflow Orchestration
    Workflow -->|3. Create Agent| TestAgentDO
    Workflow -->|4. Run Phase 1| TestAgentDO
    Workflow -->|5. Run Phase 2| TestAgentDO
    Workflow -->|6. Run Phase 3| TestAgentDO
    Workflow -->|7. Run Phase 4| TestAgentDO
    
    %% TestAgent Dependencies
    TestAgentDO -->|Launch Browser| BrowserRendering
    TestAgentDO -->|AI Requests| AIGateway
    TestAgentDO -->|Store Metadata| D1
    TestAgentDO -->|Store Decisions| AgentSQL
    TestAgentDO -->|Upload Evidence| R2
    
    %% Results Flow
    TestAgentDO -.->|8. Broadcast Progress| Browser
    DashboardWorker -->|9. Query Results| D1
    DashboardWorker -->|10. Serve Evidence| R2

    style Browser fill:#e1f5ff
    style DashboardWorker fill:#fff4e1
    style Workflow fill:#f0e1ff
    style TestAgentDO fill:#e1ffe1
    style BrowserRendering fill:#ffe1e1
    style AIGateway fill:#ffe1f5
    style D1 fill:#f5f5f5
    style AgentSQL fill:#f5f5f5
    style R2 fill:#f5f5f5
```

---

## 4-Phase Test Execution Flow

```mermaid
sequenceDiagram
    participant User as ğŸŒ User Browser
    participant DW as ğŸ“Š Dashboard Worker
    participant WF as âš™ï¸ Workflow
    participant TA as ğŸ¤– TestAgent DO
    participant BR as ğŸ® Browser Rendering
    participant AI as ğŸ§  AI Gateway
    participant D1 as ğŸ—„ï¸ D1 Database
    participant R2 as ğŸ“¦ R2 Storage

    User->>DW: Submit Game URL
    DW->>D1: Create test_run record (status: queued)
    DW->>WF: Start GameTestPipeline
    
    WF->>TA: Create DO instance (ID = test UUID)
    User->>TA: Connect WebSocket
    
    rect rgb(200, 220, 255)
        Note over WF,TA: Phase 1: Load & Validation (30s timeout)
        WF->>TA: runPhase1()
        TA->>BR: Launch browser session
        BR-->>TA: Browser ready
        TA->>BR: Navigate to game URL
        TA->>BR: Capture screenshot
        TA->>R2: Upload screenshot
        TA->>D1: Log event: "phase1 completed"
        TA-->>User: WebSocket: "Game loaded âœ“"
        TA-->>WF: Phase 1 complete
    end
    
    rect rgb(200, 255, 220)
        Note over WF,TA: Phase 2: Control Discovery (45s timeout)
        WF->>TA: runPhase2()
        TA->>BR: Stagehand.observe()
        BR-->>TA: Interactive elements found
        TA->>TA: Store in Agent SQL
        TA->>R2: Upload controls screenshot
        TA-->>User: WebSocket: "8 controls discovered"
        TA-->>WF: Phase 2 complete
    end
    
    rect rgb(255, 240, 200)
        Note over WF,TA: Phase 3: Gameplay Exploration (5min timeout)
        WF->>TA: runPhase3()
        loop Autonomous Gameplay
            TA->>AI: "What action should I take?"
            AI-->>TA: "Click play button"
            TA->>BR: Execute action
            TA->>BR: Capture screenshot
            TA->>R2: Upload evidence
            TA->>TA: Log decision in Agent SQL
            TA-->>User: WebSocket: "Testing movement..."
        end
        TA-->>WF: Phase 3 complete
    end
    
    rect rgb(255, 220, 220)
        Note over WF,TA: Phase 4: Evaluation & Scoring (60s timeout)
        WF->>TA: runPhase4()
        TA->>R2: Retrieve all screenshots
        TA->>AI: "Evaluate game quality (vision model)"
        AI-->>TA: Scores + justifications
        TA->>D1: Insert evaluation_scores
        TA->>D1: Update test_run (status: completed)
        TA-->>User: WebSocket: "Evaluation complete! Score: 85/100"
        TA-->>WF: Phase 4 complete
    end
    
    WF->>DW: Pipeline complete
    User->>DW: Request detailed report
    DW->>D1: Query scores + events
    DW->>R2: Get evidence URLs
    DW-->>User: Display full report
```

---

## Novel Pattern: TestAgent as Durable Object

```mermaid
graph LR
    subgraph "Single TestAgent Instance"
        direction TB
        State["ğŸ§  Durable Object State<br/>â€¢ Browser Session<br/>â€¢ Evidence Array<br/>â€¢ WebSocket Clients"]
        Methods["ğŸ“‹ RPC Methods<br/>â€¢ /phase1<br/>â€¢ /phase2<br/>â€¢ /phase3<br/>â€¢ /phase4<br/>â€¢ /ws"]
        AgentDB["ğŸ’¾ Agent SQL<br/>â€¢ agent_actions<br/>â€¢ control_discoveries<br/>â€¢ decision_log"]
        
        State -.-> Methods
        Methods -.-> AgentDB
    end
    
    Workflow["âš™ï¸ Workflow<br/>(Orchestrator)"]
    Browser["ğŸŒ Dashboard<br/>(Real-time UI)"]
    
    Workflow -->|"RPC: fetch phase1"| Methods
    Browser -.->|WebSocket: Live Updates| Methods
    
    Methods -->|Save Decisions| AgentDB
    Methods -->|Store Screenshots| R2[(ğŸ“¦ R2)]
    Methods -->|Log Events| D1[(ğŸ—„ï¸ D1)]
    
    style State fill:#e1ffe1
    style Methods fill:#fff4e1
    style AgentDB fill:#e1f5ff
```

**Key Benefits:**
- âœ… **Single Source of Truth:** All test state in one DO instance
- âœ… **Browser Persistence:** Session survives across phases (faster, maintains game state)
- âœ… **Built-in WebSocket:** Real-time updates without polling
- âœ… **Stateful Retry:** Workflow retries preserve TestAgent context

---

## Data Architecture

```mermaid
erDiagram
    TEST_RUNS ||--o{ EVALUATION_SCORES : "has"
    TEST_RUNS ||--o{ TEST_EVENTS : "has"
    
    TEST_RUNS {
        text id PK "UUID"
        text url
        text input_schema "JSON or NULL"
        text status "queued|running|completed|failed"
        integer overall_score "0-100"
        integer created_at
        integer updated_at
        integer completed_at
    }
    
    EVALUATION_SCORES {
        integer id PK
        text test_run_id FK
        text metric_name "load|visual|controls|playability|technical"
        integer score "0-100"
        text justification
        integer created_at
    }
    
    TEST_EVENTS {
        integer id PK
        text test_run_id FK
        text phase "phase1|phase2|phase3|phase4"
        text event_type "started|progress|completed|failed"
        text description
        integer timestamp
    }
```

**Storage Strategy:**
- **D1 (SQLite):** Cross-test metadata, queryable reports
- **Agent SQL (Per-DO):** Ephemeral per-test decisions, not shared
- **R2 (Objects):** Binary artifacts (screenshots, logs)

---

## Technology Stack Layers

```mermaid
graph TB
    subgraph "Frontend Layer"
        React["React 19.2.0<br/>+ React Router"]
        Vite["Vite 7.2.0<br/>Build Tool"]
        TailwindCSS["Tailwind CSS 3.4<br/>Styling"]
    end
    
    subgraph "Compute Layer"
        Workers["Cloudflare Workers<br/>Global Edge Runtime"]
        Workflows["Cloudflare Workflows<br/>Durable Orchestration"]
        DurableObjects["Durable Objects<br/>Stateful Agents"]
    end
    
    subgraph "Automation Layer"
        BrowserAPI["Browser Rendering API"]
        Stagehand["Stagehand 2.5.0<br/>AI Browser Control"]
        Playwright["@cloudflare/playwright"]
    end
    
    subgraph "AI Layer"
        AIGatewayBox["AI Gateway<br/>Request Router"]
        WorkersAI["Workers AI<br/>Llama Vision, Gemini"]
        ThirdPartyAI["OpenAI GPT-4o<br/>Anthropic Claude 3.5"]
    end
    
    subgraph "Data Layer"
        D1DB["D1 (SQLite)"]
        AgentSQLBox["Agent SQL"]
        R2Box["R2 Object Storage"]
    end
    
    React --> Workers
    Vite --> Workers
    Workers --> Workflows
    Workflows --> DurableObjects
    DurableObjects --> BrowserAPI
    BrowserAPI --> Stagehand
    Stagehand --> Playwright
    DurableObjects --> AIGatewayBox
    AIGatewayBox --> WorkersAI
    AIGatewayBox --> ThirdPartyAI
    DurableObjects --> D1DB
    DurableObjects --> AgentSQLBox
    DurableObjects --> R2Box
    
    style React fill:#61dafb
    style Vite fill:#646cff
    style Workers fill:#f38020
    style Workflows fill:#f6821f
    style DurableObjects fill:#f6821f
    style AIGatewayBox fill:#ff6b6b
    style D1DB fill:#003b73
    style R2Box fill:#003b73
```

---

## Communication Patterns

### 1. RPC Service Bindings (Internal Only)

```mermaid
graph LR
    DW["ğŸ“Š Dashboard Worker"]
    WF["âš™ï¸ Workflow"]
    TA["ğŸ¤– TestAgent DO"]
    
    DW -->|"env.WORKFLOW.create run"| WF
    WF -->|"env.TEST_AGENT.get fetch"| TA
    DW -->|"env.TEST_AGENT.get fetch"| TA
    
    style DW fill:#fff4e1
    style WF fill:#f0e1ff
    style TA fill:#e1ffe1
```

**No HTTP APIs Exposed** - All communication via Cloudflare service bindings

---

### 2. WebSocket Real-Time Updates

```mermaid
sequenceDiagram
    participant Browser as ğŸŒ Dashboard
    participant Worker as ğŸ“Š Worker Proxy
    participant TestAgent as ğŸ¤– TestAgent DO

    Browser->>Worker: Connect to /ws/{testId}
    Worker->>TestAgent: Proxy WebSocket
    TestAgent-->>Browser: WebSocket established
    
    loop During Test Execution
        TestAgent->>Browser: { phase: "discovery", status: "in_progress", progress: 45 }
        TestAgent->>Browser: { phase: "exploration", message: "Testing WASD controls" }
        TestAgent->>Browser: { evidence: { screenshotUrl: "..." } }
    end
    
    TestAgent->>Browser: { phase: "evaluation", status: "completed", score: 85 }
    Browser->>TestAgent: Close connection
```

**Benefits:** No polling, instant updates, browser maintains connection

---

## Error Handling & Retry Strategy

```mermaid
graph TD
    Start["Phase Execution Starts"] --> Execute["TestAgent Executes Phase"]
    Execute --> Success{Success?}
    
    Success -->|Yes| Complete["Phase Complete"]
    Success -->|No| Retry1{Retry Count < 3?}
    
    Retry1 -->|Yes| Context["Send Error Context to TestAgent"]
    Context --> Strategy["TestAgent Tries Alternative Strategy"]
    Strategy --> Execute
    
    Retry1 -->|No| Degrade{Can Degrade Gracefully?}
    
    Degrade -->|Yes| Partial["Continue with Partial Data"]
    Degrade -->|No| Fail["Mark Phase Failed"]
    
    Partial --> Complete
    
    Complete --> NextPhase{More Phases?}
    NextPhase -->|Yes| Start
    NextPhase -->|No| Done["Test Complete"]
    
    Fail --> UserError["Show User-Friendly Error"]
    
    style Complete fill:#90EE90
    style Fail fill:#FFB6C1
    style Partial fill:#FFD700
    style Strategy fill:#87CEEB
```

**Multi-Level Resilience:**
1. **Workflow Level:** Automatic exponential backoff retry (2 retries per phase)
2. **TestAgent Level:** Receives error context, adapts strategy
3. **User Level:** All errors translated to actionable messages

---

## Deployment Architecture

```mermaid
graph TB
    Developer["ğŸ‘¨â€ğŸ’» Developer"]
    Git["ğŸ“¦ Git Repository"]
    Wrangler["ğŸ”§ Wrangler CLI"]
    
    subgraph "Cloudflare Global Network"
        Edge1["ğŸŒ Edge Location 1<br/>(North America)"]
        Edge2["ğŸŒ Edge Location 2<br/>(Europe)"]
        Edge3["ğŸŒ Edge Location 3<br/>(Asia)"]
        EdgeN["ğŸŒ ... 300+ Locations"]
    end
    
    Users["ğŸ‘¥ Users Worldwide"]
    
    Developer -->|"git commit"| Git
    Developer -->|"npm run deploy"| Wrangler
    Wrangler -->|"Deploy to Edge"| Edge1
    Wrangler -->|"Deploy to Edge"| Edge2
    Wrangler -->|"Deploy to Edge"| Edge3
    Wrangler -->|"Deploy to Edge"| EdgeN
    
    Users -.->|"Routed to Nearest"| Edge1
    Users -.->|"Routed to Nearest"| Edge2
    Users -.->|"Routed to Nearest"| Edge3
    
    style Developer fill:#e1f5ff
    style Wrangler fill:#f38020
    style Edge1 fill:#f0e1ff
    style Edge2 fill:#f0e1ff
    style Edge3 fill:#f0e1ff
    style EdgeN fill:#f0e1ff
```

**Deployment Commands:**
```bash
# Deploy to production
npm run deploy  # Builds frontend + deploys Worker

# Rollback if needed
npx wrangler rollback
```

**Zero Infrastructure:**
- âœ… No CI/CD pipeline
- âœ… No container orchestration
- âœ… No load balancers
- âœ… Automatic global distribution

---

## File Organization

```
gameeval-qa-pipeline/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ index.ts                    # ğŸ“Š Dashboard Worker entry point
â”‚   â”œâ”€â”€ workers/
â”‚   â”‚   â””â”€â”€ dashboard.ts            # Frontend serving + RPC handler
â”‚   â”œâ”€â”€ workflows/
â”‚   â”‚   â””â”€â”€ gameTestPipeline.ts     # âš™ï¸ 4-phase orchestration
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â””â”€â”€ TestAgent.ts            # ğŸ¤– TestAgent Durable Object
â”‚   â”œâ”€â”€ shared/
â”‚   â”‚   â”œâ”€â”€ types.ts                # TypeScript interfaces
â”‚   â”‚   â”œâ”€â”€ constants.ts            # Config, timeouts, error messages
â”‚   â”‚   â””â”€â”€ helpers/
â”‚   â”‚       â”œâ”€â”€ r2.ts               # R2 upload/retrieval
â”‚   â”‚       â”œâ”€â”€ d1.ts               # D1 query helpers
â”‚   â”‚       â””â”€â”€ ai-gateway.ts       # AI request wrapper
â”‚   â””â”€â”€ frontend/
â”‚       â”œâ”€â”€ main.tsx                # React entry point
â”‚       â”œâ”€â”€ App.tsx                 # Dashboard UI
â”‚       â””â”€â”€ components/             # React components
â”œâ”€â”€ migrations/
â”‚   â”œâ”€â”€ 0001_create_test_runs.sql
â”‚   â”œâ”€â”€ 0002_create_evaluation_scores.sql
â”‚   â””â”€â”€ 0003_create_test_events.sql
â”œâ”€â”€ wrangler.toml                   # Cloudflare configuration
â”œâ”€â”€ package.json
â””â”€â”€ tsconfig.json
```

---

## Key Architectural Decisions (ADRs)

| ADR | Decision | Rationale |
|-----|----------|-----------|
| **ADR-001** | Monorepo with RPC-Only | Simplifies deployment, no exposed APIs |
| **ADR-002** | Single TestAgent DO Per Test | Stateful execution, persistent browser session |
| **ADR-003** | Workflow Auto-Retry with Error Awareness | Resilient testing, adaptive strategies |
| **ADR-004** | AI Gateway as Primary Entry Point | Cost optimization, automatic failover |
| **ADR-005** | Direct Wrangler Deploy (No CI/CD) | Reduces complexity, instant deployments |
| **ADR-006** | WebSocket for Real-Time Updates | Better UX than polling, instant feedback |
| **ADR-007** | Agent SQL for Ephemeral Data, D1 for Metadata | Optimized storage per use case |

---

## Scalability & Performance

```mermaid
graph LR
    subgraph "Auto-Scaling Components"
        Workers["Workers<br/>âˆ concurrent requests"]
        DO["Durable Objects<br/>1 per test (parallel)"]
        Browser["Browser Sessions<br/>Concurrent per DO"]
        R2Store["R2<br/>Unlimited storage"]
    end
    
    subgraph "Rate Limits"
        AIGatewayLimit["AI Gateway<br/>Account-level quotas"]
        WorkflowLimit["Workflows<br/>Built-in concurrency control"]
    end
    
    subgraph "Performance Optimizations"
        Cache["AI Gateway Cache<br/>15-min TTL"]
        D1Index["D1 Indexes<br/>status, created_at"]
        R2Edge["R2 Edge Caching<br/>Screenshot delivery"]
    end
    
    Workers --> DO
    DO --> Browser
    DO --> R2Store
    DO --> AIGatewayLimit
    Workers --> WorkflowLimit
    
    AIGatewayLimit --> Cache
    R2Store --> R2Edge
    
    style Workers fill:#90EE90
    style DO fill:#90EE90
    style R2Store fill:#90EE90
    style Cache fill:#FFD700
    style D1Index fill:#FFD700
    style R2Edge fill:#FFD700
```

**Expected Performance:**
- **Test Duration:** 6-8 minutes per game (4 phases)
- **Concurrent Tests:** 100+ simultaneous (limited by AI quotas)
- **Dashboard Load Time:** < 2s (edge-cached)
- **WebSocket Latency:** < 100ms (edge proximity)

---

## Summary

**Architecture Style:** Serverless Edge Computing  
**Deployment Model:** Global Edge Network  
**Communication:** RPC + WebSocket (no REST APIs)  
**State Management:** Durable Objects (strong consistency per test)  
**Data Strategy:** Tiered (D1 metadata, Agent SQL decisions, R2 artifacts)  
**Resilience:** Multi-level retry + graceful degradation  
**Monitoring:** Built-in Cloudflare Observability

**Core Strengths:**
1. âœ… **Zero Infrastructure:** No servers, VMs, or containers
2. âœ… **Auto-Scaling:** Handles 1 or 1000 tests without config changes
3. âœ… **Stateful Agents:** Browser sessions persist across phases
4. âœ… **Real-Time UX:** WebSocket updates, no polling lag
5. âœ… **Cost-Optimized:** Workers AI primary, zero egress fees

**Novel Innovations:**
1. ğŸ¯ TestAgent as Durable Object pattern
2. ğŸ¯ Event-driven progress streaming via built-in WebSocket
3. ğŸ¯ Workflow-orchestrated multi-phase testing with error recovery

---

_This diagram was generated by Winston (Architect Agent) based on the validated GameEval architecture._

